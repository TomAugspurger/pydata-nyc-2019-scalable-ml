{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Clear task state\n",
      "/opt/conda/lib/python3.7/site-packages/distributed/dashboard/core.py:72: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n",
      "distributed.scheduler - INFO -   Scheduler at:   tcp://10.20.0.131:46757\n",
      "distributed.scheduler - INFO -   dashboard at:                    :37827\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f482e5432994bb78a87dcc23fcd9f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>KubeCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    .â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "from dask_kubernetes import KubeCluster\n",
    "\n",
    "cluster = KubeCluster(n_workers=30)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-87d06a62-fa5e-11e9-8129-56d0ba869408\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.151.31:44989\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.151.31:44989\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.127.33:39423\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.127.33:39423\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.123.31:40435\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.123.31:40435\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.126.33:40923\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.126.33:40923\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.142.31:43073\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.142.31:43073\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.144.32:35787\n",
      "distributed.scheduler - INFO - Register tcp://10.20.147.33:42259\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.144.32:35787\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.147.33:42259\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.128.30:37497\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.128.30:37497\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.133.31:36231\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.133.31:36231\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.129.31:44907\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.129.31:44907\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.135.31:34889\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.135.31:34889\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.122.29:41257\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.122.29:41257\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.148.31:36553\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.148.31:36553\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.134.31:36299\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.134.31:36299\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.149.28:33261\n",
      "distributed.scheduler - INFO - Register tcp://10.20.138.31:43401\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.149.28:33261\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.125.30:46669\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.138.31:43401\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.125.30:46669\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.137.30:42153\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.137.30:42153\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.120.31:33183\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.120.31:33183\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.130.31:45959\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.130.31:45959\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.124.31:45063\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.124.31:45063\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.153.32:43855\n",
      "distributed.scheduler - INFO - Register tcp://10.20.139.32:41209\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.153.32:43855\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.139.32:41209\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.136.32:37911\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.136.32:37911\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.143.31:33083\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.143.31:33083\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.140.31:44593\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.140.31:44593\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.150.31:37177\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.150.31:37177\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.131.31:42417\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.131.31:42417\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.156.31:43643\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.156.31:43643\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.121.30:39303\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.121.30:39303\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    }
   ],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Register tcp://10.20.123.12:42071\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.123.12:42071\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.150.12:37011\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.150.12:37011\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.135.12:33541\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.135.12:33541\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.147.12:37833\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.147.12:37833\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.144.12:39619\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.144.12:39619\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.138.11:36191\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.138.11:36191\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.134.12:33039\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.134.12:33039\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.142.12:42721\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.142.12:42721\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.133.12:46017\n",
      "distributed.scheduler - INFO - Register tcp://10.20.151.12:41135\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.133.12:46017\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.151.12:41135\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.129.12:38071\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.129.12:38071\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.136.12:36525\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.136.12:36525\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.139.12:42567\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.139.12:42567\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.143.12:45619\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.143.12:45619\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.124.13:37423\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.124.13:37423\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.127.13:37799\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.127.13:37799\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.150.13:42607\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.150.13:42607\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.131.12:46449\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.131.12:46449\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.138.12:45173\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.138.12:45173\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.127.14:35499\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.127.14:35499\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.135.13:40733\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.135.13:40733\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.126.12:37109\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.126.12:37109\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.129.13:46539\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.129.13:46539\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.136.13:44047\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.136.13:44047\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.143.13:39577\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.143.13:39577\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.124.14:34235\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.124.14:34235\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.131.13:37739\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.131.13:37739\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.147.13:44559\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.147.13:44559\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.150.14:41273\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.150.14:41273\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register tcp://10.20.138.13:35083\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.20.138.13:35083\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=907</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01 00:00:00</th>\n",
       "      <td>category[unknown]</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>category[unknown]</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>category[unknown]</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02 00:00:00</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 00:00:00</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 23:59:59</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: read-parquet, 907 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                             vendor_id dropoff_datetime passenger_count trip_distance pickup_longitude pickup_latitude          rate_code dropoff_longitude dropoff_latitude       payment_type fare_amount tip_amount tolls_amount total_amount\n",
       "npartitions=907                                                                                                                                                                                                                                 \n",
       "2014-01-01 00:00:00  category[unknown]   datetime64[ns]           int64       float64          float64         float64  category[unknown]           float64          float64  category[unknown]     float64    float64      float64      float64\n",
       "2014-01-02 00:00:00                ...              ...             ...           ...              ...             ...                ...               ...              ...                ...         ...        ...          ...          ...\n",
       "...                                ...              ...             ...           ...              ...             ...                ...               ...              ...                ...         ...        ...          ...          ...\n",
       "2016-06-30 00:00:00                ...              ...             ...           ...              ...             ...                ...               ...              ...                ...         ...        ...          ...          ...\n",
       "2016-06-30 23:59:59                ...              ...             ...           ...              ...             ...                ...               ...              ...                ...         ...        ...          ...          ...\n",
       "Dask Name: read-parquet, 907 tasks"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dd.read_parquet(\"gs://dask-nyc-taxi/yellowtrip.parquet\", engine=\"fastparquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = df.partitions[0].compute()\n",
    "sdf = sdf.head(200_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2014-01-01 00:50:00</td>\n",
       "      <td>1</td>\n",
       "      <td>41.62</td>\n",
       "      <td>-73.871285</td>\n",
       "      <td>40.773962</td>\n",
       "      <td>nassau</td>\n",
       "      <td>-73.618775</td>\n",
       "      <td>41.200682</td>\n",
       "      <td>CSH</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.33</td>\n",
       "      <td>185.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2014-01-01 00:18:00</td>\n",
       "      <td>1</td>\n",
       "      <td>5.58</td>\n",
       "      <td>-73.961757</td>\n",
       "      <td>40.759820</td>\n",
       "      <td>standard</td>\n",
       "      <td>-73.978477</td>\n",
       "      <td>40.743305</td>\n",
       "      <td>CSH</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2014-01-01 00:28:00</td>\n",
       "      <td>3</td>\n",
       "      <td>6.20</td>\n",
       "      <td>-73.956543</td>\n",
       "      <td>40.778122</td>\n",
       "      <td>standard</td>\n",
       "      <td>-74.000382</td>\n",
       "      <td>40.718385</td>\n",
       "      <td>CRD</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2014-01-01 00:22:00</td>\n",
       "      <td>1</td>\n",
       "      <td>7.93</td>\n",
       "      <td>-73.979027</td>\n",
       "      <td>40.749187</td>\n",
       "      <td>standard</td>\n",
       "      <td>-73.899360</td>\n",
       "      <td>40.828842</td>\n",
       "      <td>CSH</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2014-01-01 00:03:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1.05</td>\n",
       "      <td>-73.971300</td>\n",
       "      <td>40.792705</td>\n",
       "      <td>standard</td>\n",
       "      <td>-73.959910</td>\n",
       "      <td>40.800747</td>\n",
       "      <td>CSH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                vendor_id    dropoff_datetime  passenger_count  trip_distance  \\\n",
       "pickup_datetime                                                                 \n",
       "2014-01-01            VTS 2014-01-01 00:50:00                1          41.62   \n",
       "2014-01-01            VTS 2014-01-01 00:18:00                1           5.58   \n",
       "2014-01-01            VTS 2014-01-01 00:28:00                3           6.20   \n",
       "2014-01-01            VTS 2014-01-01 00:22:00                1           7.93   \n",
       "2014-01-01            VTS 2014-01-01 00:03:00                6           1.05   \n",
       "\n",
       "                 pickup_longitude  pickup_latitude rate_code  \\\n",
       "pickup_datetime                                                \n",
       "2014-01-01             -73.871285        40.773962    nassau   \n",
       "2014-01-01             -73.961757        40.759820  standard   \n",
       "2014-01-01             -73.956543        40.778122  standard   \n",
       "2014-01-01             -73.979027        40.749187  standard   \n",
       "2014-01-01             -73.971300        40.792705  standard   \n",
       "\n",
       "                 dropoff_longitude  dropoff_latitude payment_type  \\\n",
       "pickup_datetime                                                     \n",
       "2014-01-01              -73.618775         41.200682          CSH   \n",
       "2014-01-01              -73.978477         40.743305          CSH   \n",
       "2014-01-01              -74.000382         40.718385          CRD   \n",
       "2014-01-01              -73.899360         40.828842          CSH   \n",
       "2014-01-01              -73.959910         40.800747          CSH   \n",
       "\n",
       "                 fare_amount  tip_amount  tolls_amount  total_amount  \n",
       "pickup_datetime                                                       \n",
       "2014-01-01             179.0         0.0          5.33        185.33  \n",
       "2014-01-01              17.0         0.0          0.00         18.00  \n",
       "2014-01-01              23.0         4.7          0.00         28.70  \n",
       "2014-01-01              25.0         0.0          0.00         26.00  \n",
       "2014-01-01               5.0         0.0          0.00          6.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.base\n",
    "import sklearn.ensemble\n",
    "import sklearn.compose\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['vendor_id', 'rate_code', 'payment_type']\n",
    "\n",
    "y = (sdf['tip_amount'] > 0).astype(int)\n",
    "X = sdf.drop(\"tip_amount\", axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.base\n",
    "    \n",
    "\n",
    "class DayOfWeekTransformer(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        result = X.copy()\n",
    "        for column in X.columns:\n",
    "            result[column] = X[column].dt.dayofweek\n",
    "            \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [sdf[col].cat.categories for col in cat_cols]\n",
    "onehot = sklearn.preprocessing.OneHotEncoder(categories=categories, sparse=False)\n",
    "\n",
    "dayofweek = DayOfWeekTransformer()\n",
    "\n",
    "preprocess = sklearn.compose.make_column_transformer(\n",
    "    (onehot, cat_cols),\n",
    "    (dayofweek, [\"dropoff_datetime\"]),\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "\n",
    "pipe = sklearn.pipeline.make_pipeline(\n",
    "    preprocess,\n",
    "    sklearn.ensemble.RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.27 s, sys: 191 ms, total: 9.46 s\n",
      "Wall time: 1.76 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(categorical_features=None,\n",
       "                                                                categories=[Index(['CMT', 'VTS'], dtype='object'),\n",
       "                                                                            Index(['standard', 'JFK', 'NWK', 'nassau', 'negotiated', 'group'], dtype='object'),\n",
       "                                                                            Index...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = sklearn.pipeline.make_pipeline(\n",
    "    preprocess,\n",
    "    sklearn.ensemble.RandomForestClassifier(n_estimators=1000, n_jobs=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "DaskDistributedBackend has no worker after 10 seconds. Make sure that workers are started and can properly connect to the scheduler and increase the joblib/dask connection timeout with:\n\nparallel_backend('dask', wait_for_workers_timeout=20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_dask.py\u001b[0m in \u001b[0;36meffective_n_jobs\u001b[0;34m(self, n_jobs)\u001b[0m\n\u001b[1;32m    191\u001b[0m             self.client.submit(_joblib_probe_task).result(\n\u001b[0;32m--> 192\u001b[0;31m                 timeout=self.wait_for_workers_timeout)\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# shorten error traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraiseit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"error\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m             return sync(\n\u001b[0;32m--> 762\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"timed out after %s s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: timed out after 10 s.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     message=self._log_message(name, idx, len(transformers)))\n\u001b[1;32m    419\u001b[0m                 for idx, (name, trans, column, weight) in enumerate(\n\u001b[0;32m--> 420\u001b[0;31m                         self._iter(fitted=fitted, replace_strings=True), 1))\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"Expected 2D array, got 1D array instead\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m             \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_effective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_initialize_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m             n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n\u001b[0;32m--> 710\u001b[0;31m                                              **self._backend_args)\n\u001b[0m\u001b[1;32m    711\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_timeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                 warnings.warn(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_dask.py\u001b[0m in \u001b[0;36mconfigure\u001b[0;34m(self, n_jobs, parallel, **backend_args)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbackend_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_dask.py\u001b[0m in \u001b[0;36meffective_n_jobs\u001b[0;34m(self, n_jobs)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_workers_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                      max(10, 2 * self.wait_for_workers_timeout))\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: DaskDistributedBackend has no worker after 10 seconds. Make sure that workers are started and can properly connect to the scheduler and increase the joblib/dask connection timeout with:\n\nparallel_backend('dask', wait_for_workers_timeout=20)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import joblib\n",
    "\n",
    "with joblib.parallel_backend(\"dask\"):\n",
    "    pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f482e5432994bb78a87dcc23fcd9f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>KubeCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    .â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster.scale(300)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.experimental.enable_hist_gradient_boosting\n",
    "import dask_ml.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = sklearn.pipeline.make_pipeline(\n",
    "    preprocess,\n",
    "    sklearn.ensemble.HistGradientBoostingClassifier(n_iter_no_change=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cache_cv=True, cv=3, error_score='raise',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('columntransformer',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('onehotencoder',\n",
       "                                                                         OneHotEncoder(categorical_features=None,\n",
       "                                                                                       categories=[Index(['CMT', 'VTS'], dtype='object'),\n",
       "                                                                                                   Index(['standard', 'J...\n",
       "                                                                       verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid=True, n_jobs=-1,\n",
       "             param_grid={'histgradientboostingclassifier__learning_rate': [0.009,\n",
       "                                                                           0.01,\n",
       "                                                                           0.011],\n",
       "                         'histgradientboostingclassifier__max_depth': [3, 5,\n",
       "                                                                       10],\n",
       "                         'histgradientboostingclassifier__max_iter': [90, 100,\n",
       "                                                                      110],\n",
       "                         'histgradientboostingclassifier__max_leaf_nodes': [25,\n",
       "                                                                            30,\n",
       "                                                                            35]},\n",
       "             refit=True, return_train_score=False, scheduler=None,\n",
       "             scoring=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = dict(\n",
    "    histgradientboostingclassifier__learning_rate=[0.009, 0.01, 0.011],\n",
    "    histgradientboostingclassifier__max_iter=[90, 100, 110],\n",
    "    histgradientboostingclassifier__max_leaf_nodes=[25, 30, 35],\n",
    "    histgradientboostingclassifier__max_depth=[3, 5, 10],\n",
    ")\n",
    "search = dask_ml.model_selection.GridSearchCV(pipe, param_grid, cv=3)\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[::4]\n",
    "y = y[::4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils - ERROR - An asyncio.Future, a coroutine or an awaitable is required\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/distributed/utils.py\", line 662, in log_errors\n",
      "    yield\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/distributed/dashboard/components/shared.py\", line 408, in cb\n",
      "    prof, metadata = await asyncio.gather(prof, metadata)\n",
      "  File \"/opt/conda/lib/python3.7/asyncio/tasks.py\", line 719, in gather\n",
      "    fut = ensure_future(arg, loop=loop)\n",
      "  File \"/opt/conda/lib/python3.7/asyncio/tasks.py\", line 592, in ensure_future\n",
      "    raise TypeError('An asyncio.Future, a coroutine or an awaitable is '\n",
      "TypeError: An asyncio.Future, a coroutine or an awaitable is required\n",
      "tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7f210021e710>>, <Task finished coro=<ProfileTimePlot.trigger_update.<locals>.cb() done, defined at /opt/conda/lib/python3.7/site-packages/distributed/dashboard/components/shared.py:398> exception=TypeError('An asyncio.Future, a coroutine or an awaitable is required')>)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tornado/ioloop.py\", line 767, in _discard_future_result\n",
      "    future.result()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/distributed/dashboard/components/shared.py\", line 408, in cb\n",
      "    prof, metadata = await asyncio.gather(prof, metadata)\n",
      "  File \"/opt/conda/lib/python3.7/asyncio/tasks.py\", line 719, in gather\n",
      "    fut = ensure_future(arg, loop=loop)\n",
      "  File \"/opt/conda/lib/python3.7/asyncio/tasks.py\", line 592, in ensure_future\n",
      "    raise TypeError('An asyncio.Future, a coroutine or an awaitable is '\n",
      "TypeError: An asyncio.Future, a coroutine or an awaitable is required\n",
      "Exception in callback gather.<locals>._done_callback(<Future finis...ier': 'root'}>) at /opt/conda/lib/python3.7/asyncio/tasks.py:664\n",
      "handle: <Handle gather.<locals>._done_callback(<Future finis...ier': 'root'}>) at /opt/conda/lib/python3.7/asyncio/tasks.py:664>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/conda/lib/python3.7/asyncio/tasks.py\", line 668, in _done_callback\n",
      "    if outer.done():\n",
      "NameError: free variable 'outer' referenced before assignment in enclosing scope\n",
      "distributed.utils - ERROR - An asyncio.Future, a coroutine or an awaitable is required\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/distributed/utils.py\", line 662, in log_errors\n",
      "    yield\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/distributed/dashboard/components/shared.py\", line 408, in cb\n",
      "    prof, metadata = await asyncio.gather(prof, metadata)\n",
      "  File \"/opt/conda/lib/python3.7/asyncio/tasks.py\", line 719, in gather\n",
      "    fut = ensure_future(arg, loop=loop)\n",
      "  File \"/opt/conda/lib/python3.7/asyncio/tasks.py\", line 592, in ensure_future\n",
      "    raise TypeError('An asyncio.Future, a coroutine or an awaitable is '\n",
      "TypeError: An asyncio.Future, a coroutine or an awaitable is required\n",
      "tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <zmq.eventloop.ioloop.ZMQIOLoop object at 0x7f210021e710>>, <Task finished coro=<ProfileTimePlot.trigger_update.<locals>.cb() done, defined at /opt/conda/lib/python3.7/site-packages/distributed/dashboard/components/shared.py:398> exception=TypeError('An asyncio.Future, a coroutine or an awaitable is required')>)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tornado/ioloop.py\", line 767, in _discard_future_result\n",
      "    future.result()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/distributed/dashboard/components/shared.py\", line 408, in cb\n",
      "    prof, metadata = await asyncio.gather(prof, metadata)\n",
      "  File \"/opt/conda/lib/python3.7/asyncio/tasks.py\", line 719, in gather\n",
      "    fut = ensure_future(arg, loop=loop)\n",
      "  File \"/opt/conda/lib/python3.7/asyncio/tasks.py\", line 592, in ensure_future\n",
      "    raise TypeError('An asyncio.Future, a coroutine or an awaitable is '\n",
      "TypeError: An asyncio.Future, a coroutine or an awaitable is required\n",
      "Exception in callback gather.<locals>._done_callback(<Future finis...ier': 'root'}>) at /opt/conda/lib/python3.7/asyncio/tasks.py:664\n",
      "handle: <Handle gather.<locals>._done_callback(<Future finis...ier': 'root'}>) at /opt/conda/lib/python3.7/asyncio/tasks.py:664>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/conda/lib/python3.7/asyncio/tasks.py\", line 668, in _done_callback\n",
      "    if outer.done():\n",
      "NameError: free variable 'outer' referenced before assignment in enclosing scope\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.9 s, sys: 5.97 s, total: 1min 2s\n",
      "Wall time: 2min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cache_cv=True, cv=3, error_score='raise',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('columntransformer',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('onehotencoder',\n",
       "                                                                         OneHotEncoder(categorical_features=None,\n",
       "                                                                                       categories=[Index(['CMT', 'VTS'], dtype='object'),\n",
       "                                                                                                   Index(['standard', 'J...\n",
       "                                                                       verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid=True, n_jobs=-1,\n",
       "             param_grid={'histgradientboostingclassifier__learning_rate': [0.009,\n",
       "                                                                           0.01,\n",
       "                                                                           0.011],\n",
       "                         'histgradientboostingclassifier__max_depth': [3, 5,\n",
       "                                                                       10],\n",
       "                         'histgradientboostingclassifier__max_iter': [90, 100,\n",
       "                                                                      110],\n",
       "                         'histgradientboostingclassifier__max_leaf_nodes': [25,\n",
       "                                                                            30,\n",
       "                                                                            35]},\n",
       "             refit=True, return_train_score=False, scheduler=None,\n",
       "             scoring=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time search.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57558"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Remove worker tcp://10.20.139.34:33503\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.139.34:33503\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.123.33:45221\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.123.33:45221\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.149.34:40993\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.149.34:40993\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.151.40:35217\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.151.40:35217\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.144.35:44993\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.144.35:44993\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.153.41:36999\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.153.41:36999\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.130.33:39237\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.130.33:39237\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.135.33:46387\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.135.33:46387\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.138.38:34817\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.138.38:34817\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.137.39:41165\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.137.39:41165\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.131.35:38885\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.131.35:38885\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.128.31:42723\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.128.31:42723\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.126.42:46661\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.126.42:46661\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.127.41:37589\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.127.41:37589\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.127.34:41611\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.127.34:41611\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.148.40:41295\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.148.40:41295\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.148.39:42431\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.148.39:42431\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.148.37:44569\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.148.37:44569\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.133.38:37747\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.133.38:37747\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.150.38:37477\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.150.38:37477\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.138.33:37145\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.138.33:37145\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.129.35:33357\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.129.35:33357\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.130.40:35671\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.130.40:35671\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.151.38:43533\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.151.38:43533\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.153.39:38395\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.153.39:38395\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.133.35:38677\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.133.35:38677\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.144.40:46233\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.144.40:46233\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.147.40:33193\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.147.40:33193\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.124.34:36581\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.124.34:36581\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.133.31:36231\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.133.31:36231\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.142.37:34015\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.142.37:34015\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.120.31:33183\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.120.31:33183\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.139.40:44681\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.139.40:44681\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.156.34:41139\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.156.34:41139\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.148.32:39945\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.148.32:39945\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.120.39:35231\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.120.39:35231\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.149.37:34375\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.149.37:34375\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.144.41:43297\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.144.41:43297\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.147.39:44483\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.147.39:44483\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.149.33:46877\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.149.33:46877\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.125.39:37413\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.125.39:37413\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.143.33:40451\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.143.33:40451\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.148.33:33471\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.148.33:33471\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.125.37:41723\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.125.37:41723\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.142.38:34661\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.142.38:34661\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.122.38:33505\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.122.38:33505\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.122.37:42667\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.122.37:42667\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.121.32:41565\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.121.32:41565\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.122.29:41257\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.122.29:41257\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.139.38:35443\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.139.38:35443\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.144.34:45365\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.144.34:45365\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.147.35:36435\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.147.35:36435\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.131.40:39179\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.131.40:39179\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.136.33:36447\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.136.33:36447\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.122.30:36957\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.122.30:36957\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.131.32:33167\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.131.32:33167\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.137.38:35313\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.137.38:35313\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.134.37:42635\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.134.37:42635\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.120.32:41989\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.120.32:41989\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.121.39:39023\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.121.39:39023\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.124.33:41825\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.124.33:41825\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.135.34:33499\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.135.34:33499\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.121.37:34465\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.121.37:34465\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.147.38:34929\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.147.38:34929\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.143.31:33083\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.143.31:33083\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.136.41:40035\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.136.41:40035\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.140.34:44051\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.140.34:44051\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.128.30:37497\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.128.30:37497\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.127.38:43323\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.127.38:43323\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.151.32:44195\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.151.32:44195\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.134.38:45263\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.134.38:45263\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.130.36:43113\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.130.36:43113\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.122.35:35403\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.122.35:35403\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.124.32:40931\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.124.32:40931\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.123.35:41647\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.123.35:41647\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.137.31:34173\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.137.31:34173\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.138.34:37341\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.138.34:37341\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.150.32:33975\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.150.32:33975\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.150.39:40885\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.150.39:40885\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.153.35:40133\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.153.35:40133\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.150.35:45753\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.150.35:45753\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.134.39:36683\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.134.39:36683\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.150.36:39103\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.150.36:39103\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.148.34:35539\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.148.34:35539\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.120.34:43761\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.120.34:43761\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.122.33:32985\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.122.33:32985\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.121.35:42973\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.121.35:42973\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.120.38:35895\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.120.38:35895\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.125.31:43727\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.125.31:43727\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.130.39:37345\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.130.39:37345\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.130.35:32807\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.130.35:32807\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.122.32:34917\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.122.32:34917\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.143.38:37371\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.143.38:37371\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.140.36:35963\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.140.36:35963\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.127.37:44459\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.127.37:44459\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.133.36:38591\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.133.36:38591\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.156.35:44461\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.156.35:44461\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.127.39:34379\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.127.39:34379\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.150.33:43635\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.150.33:43635\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.137.36:42419\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.137.36:42419\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.138.36:46089\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.138.36:46089\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.148.31:36553\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.148.31:36553\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.131.37:41487\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.131.37:41487\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.125.33:36371\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.125.33:36371\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.149.32:39415\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.149.32:39415\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.156.33:36947\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.156.33:36947\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.128.32:36417\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.128.32:36417\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.128.37:33587\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.128.37:33587\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.148.36:45081\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.148.36:45081\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.150.37:39755\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.150.37:39755\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.136.37:43715\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.136.37:43715\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.136.38:33363\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.136.38:33363\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.125.36:42431\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.125.36:42431\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.156.40:46157\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.156.40:46157\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.149.31:39653\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.149.31:39653\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.121.38:36635\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.121.38:36635\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.137.32:39057\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.137.32:39057\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.142.35:45681\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.142.35:45681\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.144.38:46681\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.144.38:46681\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.156.36:37325\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.156.36:37325\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.125.32:41001\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.125.32:41001\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.150.40:45507\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.150.40:45507\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.144.33:35343\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.144.33:35343\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.147.36:33185\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.147.36:33185\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.137.35:34289\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.137.35:34289\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.134.40:33395\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.134.40:33395\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.153.32:43855\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.153.32:43855\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.142.34:40235\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.142.34:40235\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.124.35:35979\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.124.35:35979\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.136.40:36547\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.136.40:36547\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.140.37:40893\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.140.37:40893\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.147.37:35909\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.147.37:35909\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.126.38:37097\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.126.38:37097\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.121.33:38887\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.121.33:38887\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.134.34:39133\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.134.34:39133\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.130.37:45701\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.130.37:45701\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.135.39:44109\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.135.39:44109\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.123.37:36867\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.123.37:36867\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.129.32:38793\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.129.32:38793\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.126.39:32949\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.126.39:32949\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.120.37:38805\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.120.37:38805\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.138.32:38823\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.138.32:38823\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.139.39:41889\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.139.39:41889\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.123.38:45879\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.123.38:45879\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.124.36:34785\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.124.36:34785\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.130.38:45367\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.130.38:45367\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.129.38:45899\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.129.38:45899\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.131.33:37209\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.131.33:37209\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.126.36:40185\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.126.36:40185\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.127.36:35709\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.127.36:35709\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.125.30:46669\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.125.30:46669\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.156.31:43643\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.156.31:43643\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.129.39:34831\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.129.39:34831\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.131.39:35985\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.131.39:35985\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.134.33:46743\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.134.33:46743\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.140.38:35451\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.140.38:35451\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.127.33:39423\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.127.33:39423\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.128.36:36077\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.128.36:36077\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.151.35:37087\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.151.35:37087\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.136.34:40503\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.136.34:40503\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.124.37:42047\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.124.37:42047\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.133.37:38851\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.133.37:38851\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.135.37:46865\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.135.37:46865\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.139.41:45411\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.139.41:45411\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.143.40:43015\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.143.40:43015\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.126.34:44847\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.126.34:44847\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.133.33:41703\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.133.33:41703\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.144.37:35243\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.144.37:35243\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.153.33:44639\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.153.33:44639\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.137.37:34779\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.137.37:34779\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.149.36:42275\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.149.36:42275\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.140.33:46779\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.140.33:46779\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.153.37:37023\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.153.37:37023\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.124.39:37303\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.124.39:37303\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.144.39:43181\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.144.39:43181\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.139.33:38179\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.139.33:38179\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.129.34:39551\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.129.34:39551\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.130.34:35295\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.130.34:35295\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.137.33:45985\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.137.33:45985\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.121.31:45729\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.121.31:45729\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.151.31:44989\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.151.31:44989\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.143.32:45315\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.143.32:45315\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.135.36:33215\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.135.36:33215\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.123.40:38639\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.123.40:38639\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.122.34:36913\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.122.34:36913\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.136.32:37911\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.136.32:37911\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.123.36:45047\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.123.36:45047\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.151.34:39533\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.151.34:39533\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.128.35:41063\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.128.35:41063\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.126.33:40923\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.126.33:40923\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.144.32:35787\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.144.32:35787\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.149.30:37603\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.149.30:37603\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.121.30:39303\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.121.30:39303\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.135.40:42725\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.135.40:42725\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.120.36:40621\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.120.36:40621\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.133.34:34139\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.133.34:34139\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.137.30:42153\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.137.30:42153\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.134.36:33137\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.134.36:33137\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.130.32:41823\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.130.32:41823\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.131.31:42417\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.131.31:42417\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.143.36:35663\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.143.36:35663\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.128.38:36693\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.128.38:36693\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.142.31:43073\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.142.31:43073\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.147.41:34967\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.147.41:34967\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.127.42:41273\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.127.42:41273\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.127.35:44429\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.127.35:44429\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.120.33:40849\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.120.33:40849\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.140.40:45625\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.140.40:45625\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.143.34:41119\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.143.34:41119\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.147.34:40063\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.147.34:40063\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.153.40:34829\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.153.40:34829\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.128.34:41137\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.128.34:41137\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.120.40:45443\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.120.40:45443\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.131.34:46147\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.131.34:46147\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.134.31:36299\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.134.31:36299\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.123.32:46591\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.123.32:46591\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.156.38:37703\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.156.38:37703\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.151.39:36623\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.151.39:36623\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.136.35:44727\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.136.35:44727\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.156.39:34473\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.156.39:34473\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.128.39:36575\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.128.39:36575\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.126.40:36925\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.126.40:36925\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.125.35:39391\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.125.35:39391\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.138.35:45139\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.138.35:45139\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.126.35:33115\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.126.35:33115\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.150.31:37177\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.150.31:37177\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.121.36:42669\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.121.36:42669\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.128.33:46753\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.128.33:46753\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.122.36:33339\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.122.36:33339\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.138.39:37937\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.138.39:37937\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.151.37:40123\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.151.37:40123\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.151.36:33253\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.151.36:33253\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.135.35:44715\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.135.35:44715\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.129.31:44907\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.129.31:44907\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.135.38:41235\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.135.38:41235\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.123.31:40435\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.123.31:40435\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.121.34:39365\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.121.34:39365\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.156.32:46519\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.156.32:46519\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.139.36:34929\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.139.36:34929\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.150.34:45297\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.150.34:45297\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.131.38:39715\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.131.38:39715\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.126.37:36801\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.126.37:36801\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.151.33:44077\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.151.33:44077\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.143.39:32955\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.143.39:32955\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.149.28:33261\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.149.28:33261\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.153.36:37487\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.153.36:37487\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.139.35:41113\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.139.35:41113\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.136.36:34209\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.136.36:34209\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.129.36:34799\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.129.36:34799\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.126.41:37321\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.126.41:37321\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.129.40:45857\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.129.40:45857\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.144.36:33933\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.144.36:33933\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.140.35:36605\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.140.35:36605\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.153.38:42377\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.153.38:42377\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.142.33:34319\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.142.33:34319\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.156.37:34413\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.156.37:34413\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.134.32:35295\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.134.32:35295\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.122.31:41989\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.122.31:41989\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.138.40:36803\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.138.40:36803\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.139.32:41209\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.139.32:41209\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.140.39:33321\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.140.39:33321\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.142.40:38689\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.142.40:38689\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.123.34:41001\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.123.34:41001\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.129.37:38449\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.129.37:38449\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.143.37:44439\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.143.37:44439\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.139.37:42391\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.139.37:42391\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.140.31:44593\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.140.31:44593\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.142.36:36067\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.142.36:36067\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.133.39:38681\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.133.39:38681\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.135.32:34931\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.135.32:34931\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.148.38:46029\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.148.38:46029\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.131.36:46051\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.131.36:46051\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.137.34:41887\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.137.34:41887\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.125.38:40781\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.125.38:40781\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.124.40:36975\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.124.40:36975\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.147.33:42259\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.147.33:42259\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.143.35:45235\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.143.35:45235\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.153.34:46529\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.153.34:46529\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.140.32:33343\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.140.32:33343\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.120.35:38855\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.120.35:38855\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.142.32:39445\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.142.32:39445\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.142.39:46229\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.142.39:46229\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.149.29:46511\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.149.29:46511\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.125.34:45305\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.125.34:45305\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.147.42:46199\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.147.42:46199\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.133.40:36409\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.133.40:36409\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.130.31:45959\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.130.31:45959\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.138.37:44253\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.138.37:44253\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.123.39:42669\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.123.39:42669\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.124.31:45063\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.124.31:45063\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.148.35:44225\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.148.35:44225\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.133.32:38035\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.133.32:38035\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.127.40:41645\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.127.40:41645\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.135.31:34889\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.135.31:34889\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.134.35:41851\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.134.35:41851\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.138.31:43401\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.138.31:43401\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.149.35:43505\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.149.35:43505\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.129.33:45759\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.129.33:45759\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.136.39:45679\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.136.39:45679\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.20.124.38:32913\n",
      "distributed.core - INFO - Removing comms to tcp://10.20.124.38:32913\n",
      "distributed.scheduler - INFO - Lost all workers\n"
     ]
    }
   ],
   "source": [
    "cluster.scale(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9971"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.score(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
